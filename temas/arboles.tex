\newpage
\section{Arboles}

Un \emph{\'arbol} es un grafo conexo sin circuitos simples. Dado $G=(V,X)$ las siguientes afirmaciones son equivalentes:

\begin{enumerate}
\item $G$ es un \'arbol.
\item $G$ es un grafo sin circuitos simples, pero si se le agrega una arista $e$ a $G$ tenemos un grafo con exactamente un circuito simple, y ese circuito contiene a $e$.
\item Existe exactamente un camino simple entre todo par de nodos.
\item $G$ es conexo, pero si se le quita una cualquier arista queda disconexo.
\end{enumerate}

Sea $G=(V,X)$ un grafo conexo y $e \in X$, $G-e$ es conexo si y s\'olo si $e$ pertenece a un circuito simple de $G$. Dentro de un \'arbol, definimos como \emph{hoja} a un nodo de grado 1. Todo \'arbol no trivial tiene al menos 2 hojas.

\subsection{Propiedades de los \'arboles}

\begin{itemize}
\item Si $G$ un \'arbol, entonces $m=n-1$.
\item Si $G = (V,X)$ con $c$ componentes conexas, entonces $m \geq n-c$.
\item Si $G = (V,X)$ con $c$ componentes conexas y sin circuitos simples, entonces $m=n-c$.
\end{itemize}

\subsection{Arboles enraizados}

En un \'arbol no dirigido podemos definir un nodo cualquiera como ra\'iz. El \emph{nivel} de un v\'ertice de un \'arbol es la distancia de ese v\'ertice a la raiz. La \emph{altura} $h$ de un \'arbol es la longitud desde la raiz hasta el v\'ertice m\'as lejano. 

Un \'arbol se dice \emph{``$m$-ario''} (con $m \geq 2$) si todos sus v\'ertices salvo las hojas y la raiz tienen grado a lo sumo $m+1$ y la raiz a lo sumo $m$.

Un \'arbol se dice \emph{``balanceado''} si todas sus hojas est\'an a nivel $h$ o $h-1$. Si todas est\'an a nivel $h$, se dice que es \emph{``balanceado completo''}.

Los nodos \emph{``internos''} de un \'arbol son aquellos que no son hojas ni ra\'iz.

\begin{itemize}
\item Un \'arbol $m$-ario de altura $h$ tiene a lo sumo $m^h$ hojas. 
\item Un \'arbol $m$-ario de altura $h \geq 1$ y balanceado completo tiene exactamente $m^h$ hojas.
\item Un \'arbol $m$-ario con $l$ hojas tiene $h \geq \lceil log_{m}l \rceil$.
\item Un \'arbol exactamente $m$-ario balanceado con $l$ hojas tiene $h = \lceil log_{m}l \rceil$.
\end{itemize}

\subsection{Recorrido de \'arboles}
\subsubsection{DFS}

\emph{``Depth First Search''} es un algoritmo de b\'usqueda en grafos. Lo que hace es arrancar desde un v\'ertice $n$ cualquiera y fijarse si dicho v\'ertice es el que estamos buscando. Si no lo es, marcarlo como visitado, pedir el listado de todos sus vecinos y llamarse recursivamente ($DFSr$) en cada uno de ellos.
\vspace{8px}

\begin{algorithm}
\begin{algorithmic}[1]
\Function{DFS}{$G = (V, E)$}
  \ForAll{$v \in V$}
    \State $visitV_v \gets false$
  \EndFor
  \ForAll{$e \in E$}
    \State $visitE_e \gets false$
  \EndFor
  \ForAll{$v \in V$}
    \If{$visitV_v = false$}
      \State $DFS(v)$
    \EndIf
  \EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\begin{algorithmic}[1]
\Function{DFS}{$v$}
  \State $visited_v \gets true$
  \ForAll{$e = (w,u) \in E$ \textbf{where} $w = v$ \textbf{and} $visitE_e = false$}
    \If{$visitV_w = false$}
      \State $DFS(w)$
    \EndIf
  \EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}

Cuando el algoritmo llega a una hoja hace backtracking hasta el \'ultimo v\'ertice revisado con hijos todav\'ia sin revisar.

Como todos los algoritmos de grafos, la complejidad depende de ciertos factores de la implementaci\'on. En la funci\'on $DFS(v)$ estoy recorriendo todos los ejes de $E$, buscando los que salen de $v$. Si hago este llamado para cada v\'ertice $v$, la complejidad del algoritmo me va a quedar $O(n * m)$.

No obstante, no queremos recorrer ejes que ya sabemos que ya revisamos. Es verdad que, como mucho, podr\'iamos iterar $m$ veces en la linea $3:$, pero en una buena implementaci\'on de DFS no tendr\'iamos que nunca pasar por el mismo eje dos veces.

Es decir, por cada v\'ertice, solo vamos a ver sus ejes no visitados. Si queremos revisar todos los v\'ertices y todos los ejes de cada uno, nos temina quedando una complejidad de $O(n + m)$.

\newpage
\subsubsection{BFS}

\emph{``Bradth First Search''} es muy similar a DFS pero, en lugar de realizar backtracking poniendo todos los vecinos de cada v\'ertice en un stack, pone a todos los vecinos de cada v\'ertice en una queue.
\vspace{8px}

\begin{center}
\begin{minipage}{0.78\textwidth}
\begin{lstlisting}[frame=lrtb]
void BFS(Graph &g, int n) {
  queue<int> q;
  bool checked[g.n];
  memset(checked, 0, sizeof(checked));
  q.push(0);

  while(!q.empty()) {
    int t = q.front();
    q.pop();

    if(checked[t]) continue;
    if(t == n) {
      cout << "found!" << endl;
      return;
    }

    checked[t] = 1;
    vector<int> neigh = g.getAdyacents(t); 
    for(int i = 0; i < neigh.size(); ++i) {
      if(!checked[neigh[i]]) {
        q.push(neigh[i]);
      }
    }
  }

}
\end{lstlisting}
\end{minipage}
\end{center}

Al igual que con DFS, BFS s\'olo tiene sentido en grafos conexos y tiene complejidad $O(n)$.

\newpage
\subsection{Arbol generador}

Dado un grafo conexo $G$, un \emph{``\'arbol generador''} de $G$ es un subgrafo de $G$ que es un \'arbol y tiene el mismo conjunto de v\'ertices. Si los ejes del grafo tienen peso, entonces cada \'arbol generador va a tener una determinada \emph{``longitud''}, que se define como la suma de todos los pesos de sus ejes. Cuando dicha longitud es m\'inima, decimos que tenemos un \emph{``\'arbol generador m\'inimo''}.

\raggedright
  \bigskip
  \begin{center}
\begin{tikzpicture}[shorten >=1pt, auto, node distance=3cm,
   node_style/.style={circle},
   edge_style/.style={draw=black},
   edge_styly/.style={draw=green, ultra thick}]




\node[vertex] (n2) at (3,4)  {B};
\node[vertex] (n3) at (5,4)  {C};
\node[vertex] (n4) at (7,4)  {D};

\node[vertex] (n9) at (5,2)  {I};
\node[vertex] (n1) at (1,2)  {A};
\node[vertex] (n5) at (9,2)  {E};

\node[vertex] (n6) at (7,0)  {F};
\node[vertex] (n7) at (5,0)  {G};
\node[vertex] (n8) at (3,0)  {H};
    
\draw[edge_styly]  (n1) edge node{4} (n2);
\draw[edge_style]  (n1) edge node{8} (n8);
\draw[edge_style]  (n2) edge node{12} (n8);
\draw[edge_styly]  (n2) edge node{8} (n3);
\draw[edge_style]  (n8) edge node{6} (n9);
\draw[edge_styly]  (n8) edge node{1} (n7);
\draw[edge_styly]  (n7) edge node{3} (n6);
\draw[edge_style]  (n7) edge node{5} (n9);
\draw[edge_styly]  (n9) edge node{3} (n3);
\draw[edge_styly]  (n3) edge node{6} (n4);
\draw[edge_styly]  (n3) edge node{4} (n6);
\draw[edge_style]  (n4) edge node{13} (n6);
\draw[edge_styly]  (n4) edge node{9} (n5);
\draw[edge_style]  (n6) edge node{10} (n5);


  %\draw(n1) -- (n2);
  %\draw(n1) -- (n8);

  %\draw(n2) -- (n8);
  %\draw(n2) -- (n3);
  
  %\foreach \from/\to in {n1/n2,n1/n3,n1/n5,n2/n1,n2/n3,n2/n4,n2/n5,n2/n6,n3/n1,n3/n2,n3/n5,n3/n6,n4/n2,n4/n5,n4/n6,n5/n1,n5/n2,n5/n3,n5/n4,n5/n6,n6/n2,n6/n3,n6/n4,n6/n5}
  %\draw (\from) -- (\to);

  \end{tikzpicture}
  \end{center}

\newpage
\subsubsection{Algoritmo de Kruskal}

El algoritmo de Kruskal es un algoritmo greedy que lo que hace es ir seleccionando las aristas que van a conformar el AGM una por una, arrancando de la de menor peso y subiendo progresivamente. Si el grafo no es conexo, forma un \emph{``bosque generador m\'inimo''}.

\begin{algorithm}
\caption{Algoritmo de Kruskal}
\begin{algorithmic}[1]
\State $AGM \gets \emptyset$
\ForAll{$v \in V$}
  \State makeDisjointSet($V$)
\EndFor
\State sortByWeightASC($E$)
\ForAll{$(v_1, v_2)  \in E$}
  \If {find($v_1$) \neq find($v_2$)}
    \State $AGM \gets AGM \cup (v_1, v_2)$
    \State union($v_1, v_2$)
  \EndIf
\EndFor
\Return $AGM$
\end{algorithmic}
\end{algorithm}

\subsubsection*{Explicaci\'on}

\begin{enumerate}
\item [1:] Empieza declarando un $AGM$ vac\'io. Este va a ser un conjunto de ejes, que es lo que va a devolver el algoritmo.
\item [2: y 3:] Crea un conjunto disjunto para cada v\'ertice de $V$.
\item [4:] Ordena ascendentemente a todos los ejes por peso.
\item [5:] Empieza a iterar por todos los ejes $(v_1, v_2)$ de $E$
  \begin{enumerate}
  \item [6:] Para cada eje, se fija que $v_1$ y $v_2$ est\'en en diferentes conjuntos del disjoint set previamente creado.
    \begin{enumerate}
    \item [7:] Si no lo est\'an, agrega a $(v_1, v_2)$ al $AGM$.
    \item [8:] Y los une adentro del disjoint set.
    \end{enumerate}
  \end{enumerate}
\end{enumerate}

\subsubsection*{Complejidad}

En cada iteraci\'on del algoritmo (5:) necesitamos poder obtener el eje no todav\'ia insertado en el AGM en O(1). Esto se puede lograr f\'acilmente ordenando todos los $m$ ejes por peso ascendentemente usando alg\'un sort por comparaci\'on, lo cual se puede hacer en O(m log m) (4:).

Los pasos 6: y 8: (find y union) se pueden hacer en O(log m). Como los estoy haciendo en cada iteraci\'on del algoritmo, y como voy a iterar n-1 veces, la complejidad del mismo termina siendo O(n (2 log m)) = O(n log m).

\newpage
\subsubsection{Algoritmo de Prim}

Al igual que el algoritmo de Kruskal, el algoritmo de Prim nos permite encontrar un \'arbol generador m\'inimo para un grafo. Este es un pseudoc\'odigo del mismo:

\begin{algorithm}
\caption{Algoritmo de Prim}
\begin{algorithmic}[1]
\State $AGM \gets \emptyset$
\State $V \gets \{ v \}$
\While{$|V| \neq n$}
  \State $(v_1, v_2) \gets$ buscarEje($V$)
  \State $AGM \gets AGM \cup \{ (v_1, v_2) \}$
  \State $V \gets V \cup \{ v_2 \}$
\EndWhile
\Return $AGM$
\end{algorithmic}
\end{algorithm}

\subsubsection*{Explicaci\'on}

A diferencia del anterior, el algoritmo de Pimm hace crecer al AGM desde un v\'ertice raiz arbitrario, y agrega un eje nuevo en cada iteraci\'on. El algoritmo termina cuando todos los v\'ertices est\'an en el AGM. El pseudoc\'odigo funciona de la siguiente manera:

\begin{enumerate}
\item [1:] Declaramos el AGM que vamos a devolver como vac\'io. Al igual que en el algorimto de Kruskal, el AGM devuelto es un conjunto de ejes.
\item [2:] Creamos un conjunto $V$ de v\'ertices que s\'olo tiene a un v\'ertice arbitrario $v$, que puede ser cualquiera.
\item [3:] Vamos a iterar hasta que $V$ tenga a todos los v\'ertices del grafo.
\item [4:] Obtenemos un eje $(v_1, v_2)$ usando una funci\'on llamada buscarEje. El eje devuelto tiene que cumplir las siguientes propiedades:
  \begin{itemize}
  \item $v_1 \in V$
  \item $v_2 \not \in V$
  \item El peso de $(v_1, v_2)$ tiene que ser m\'inimo.
  \end{itemize}
\item [5:] Agregamos a $(v_1, v_2)$ a nuestro AGM.
\item [6:] Agregamos a $v_2$ a $V$.
\end{enumerate}

\subsubsection*{Complejidad}

L\'ogicamente toda la complejidad del algoritmo est\'a en la funci\'on buscarEje, la cual hace que el algoritmo sea greddy. La complejidad del mismo depende de las estructura utilizada para implementar la funci\'on buscarEje.

Si utilizo una cola de prioridad implementada sobre un min-heap binario esta funci\'on cuesta O(log m). Como este paso se va a tener que realizar n veces ya que est\'a adentro del while, el costo total del algoritmo es de O(n log m).